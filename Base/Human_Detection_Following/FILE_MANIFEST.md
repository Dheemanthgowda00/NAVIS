# üìã Human_Detection_Following Module - File Manifest

## Module Overview
Complete autonomous human detection and following system for NAVIS robot using MediaPipe pose detection, OpenCV camera streaming, and MQTT robot control.

**Location**: `/home/navis/NAVIS/Base/Human_Detection_Following/`
**Status**: ‚úÖ Complete & Ready
**Implementation Date**: 28 January 2026
**Python Version**: 3.10.0
**Total Files**: 8 (3 Python, 3 Documentation, 1 HTML, 1 Requirements)

---

## üìÅ File Structure & Contents

### Core Application Files

#### `app.py` (312 lines)
**Purpose**: Main Flask application with MediaPipe integration
**Language**: Python 3
**Dependencies**: Flask, OpenCV, MediaPipe, paho-mqtt, NumPy

**Key Components**:
- **MediaPipe Setup**: Holistic pose detection with 33 landmarks
- **Position Detection**: Analyzes horizontal position (LEFT/CENTER/RIGHT)
- **Depth Estimation**: Calculates distance using shoulder width
- **Command Generation**: Decision logic for MQTT commands
- **MQTT Integration**: Publishes commands to robot/control topic
- **Flask Routes**:
  - `GET /` - Serve main HTML page
  - `GET /video_feed` - Stream video frames (MJPEG)
  - `GET /status` - Return current detection status (JSON)
  - `POST /set_threshold` - Update depth thresholds
- **Video Streaming**: Real-time camera feed with pose overlay
- **Configuration**: Adjustable detection parameters

**Key Functions**:
```python
send_mqtt_command(cmd, speed)       # Publish MQTT message
analyze_pose(frame, results)        # Detect position & depth
generate_frames()                   # Video streaming generator
```

**Configuration Constants**:
```python
FRAME_WIDTH = 640                   # Camera width (pixels)
FRAME_HEIGHT = 480                  # Camera height (pixels)
FPS = 30                           # Target frame rate
CENTER_TOLERANCE = 0.15            # ¬±15% center zone
DEPTH_THRESHOLD_NEAR = 0.3         # < 30% = NEAR
DEPTH_THRESHOLD_FAR = 0.7          # > 70% = FAR
```

---

#### `templates/index.html` (450+ lines)
**Purpose**: Web interface for real-time monitoring and control
**Language**: HTML5 + CSS3 + JavaScript
**Framework**: Vanilla JavaScript (no external libraries)

**Sections**:
1. **Header**: Title and subtitle
2. **Video Container**: Live MJPEG stream from Flask
3. **Control Panel**:
   - Detection status indicator (red/green)
   - Position display (LEFT/CENTER/RIGHT)
   - Depth display (NEAR/MEDIUM/FAR)
   - Distance percentage (0-100%)
   - FPS counter
   - Command display (F/B/L/R/S)
4. **Threshold Controls**: Dual sliders for depth adjustment
5. **Information Box**: Behavior explanation
6. **Legend**: Color coding reference

**CSS Features**:
- Dark theme (#1a1a1a background)
- Gradient text (green to cyan)
- Smooth animations
- Responsive design (works on mobile)
- Box shadows and glows
- Custom slider styling

**JavaScript Features**:
```javascript
updateStatus()           // Fetch /status every 500ms
updateThreshold()        // Post threshold changes to /set_threshold
Auto-update status       // Real-time indicator changes
```

**Styling**:
- Green (#00ff88) for detection/success
- Cyan (#00ccff) for info/status
- Orange (#ff6600) for commands
- Responsive grid layout
- 16:9 video aspect ratio

---

### Testing & Debugging Tools

#### `test_setup.py` (65 lines)
**Purpose**: Verify all system dependencies and connectivity
**Language**: Python 3
**No Dependencies**: Uses only subprocess module

**Tests Performed**:
1. **Camera Test**: Checks if camera is accessible and working
2. **MediaPipe Test**: Verifies import and model loading
3. **OpenCV Test**: Confirms OpenCV installation
4. **MQTT Test**: Tests broker connectivity and message publishing

**Output Example**:
```
‚úì Camera working: Resolution 640x480
‚úì MediaPipe imported successfully
‚úì Holistic model loaded
‚úì Pose detection working
‚úì OpenCV version: 4.8.1.78
‚úì MQTT broker connected
‚úì Test message published

‚úì All systems ready!
```

---

#### `viewer.py` (155 lines)
**Purpose**: Standalone pose viewer without web server (for debugging)
**Language**: Python 3
**Dependencies**: OpenCV, MediaPipe, NumPy

**Features**:
- Real-time skeleton overlay
- Zone visualization (LEFT/CENTER/RIGHT)
- Depth bar with threshold indicators
- Frame counter
- No web server (direct camera view)

**Controls**:
- `q` - Quit application
- `r` - Reset camera connection

**Use Case**: Test MediaPipe and camera without Flask overhead

---

### Configuration & Dependencies

#### `requirements.txt` (10 lines)
**Purpose**: Specify all Python package dependencies for pip install

**Packages**:
```
Flask==3.1.2              # Web framework
opencv-python==4.8.1.78   # Computer vision library
mediapipe==0.10.8         # Pose detection
paho-mqtt==2.1.0          # MQTT client
numpy==1.24.3             # Numerical computing
```

**Installation**:
```bash
pip install -r requirements.txt
```

**Note**: OpenCV and MediaPipe are large (~500 MB total) and take 5-10 minutes to install on Raspberry Pi

---

### Documentation Files

#### `QUICKSTART.md` (180 lines)
**Purpose**: 5-minute setup and running guide
**Audience**: Users wanting quick deployment

**Sections**:
1. Installation steps
2. Testing procedure
3. Starting the application
4. Expected behavior (no person, far, near, center, left, right)
5. Threshold adjustment guide
6. MQTT monitoring
7. Running both modules simultaneously
8. Testing checklist
9. Web interface features
10. Quick troubleshooting

---

#### `IMPLEMENTATION_GUIDE.md` (450+ lines)
**Purpose**: Comprehensive technical documentation
**Audience**: Developers and technical integrators

**Content**:
1. Complete architecture diagram
2. Detection algorithms (position & depth)
3. Command decision tree
4. Hardware integration details
5. Message format specification
6. Configuration options
7. Performance specifications
8. Testing checklist
9. Troubleshooting table
10. File descriptions
11. Learning resources
12. Future enhancements

---

#### `SETUP_COMPLETE.md` (280+ lines)
**Purpose**: Setup completion summary and verification
**Audience**: Setup verification and status check

**Content**:
1. What was created
2. How it works
3. Decision matrix
4. Quick commands
5. System specifications
6. Integration points
7. Key features list
8. Testing procedures
9. Hardware requirements
10. Known limitations
11. Success criteria

---

### Additional Documentation (in main README.md)

**Location**: `/home/navis/NAVIS/README.md`
**Sections Added**:
- Complete module description
- Features and capabilities
- Installation instructions
- Running instructions
- Configuration details
- Requirements list

---

## üîß Technical Specifications

### System Requirements
- **OS**: Linux (Debian Bookworm)
- **Python**: 3.10.0
- **Architecture**: ARM64 (Raspberry Pi 4B+)
- **Memory**: 512 MB minimum (1 GB recommended)
- **Disk Space**: 500 MB for dependencies

### Network Requirements
- **WiFi**: 2.4GHz connection
- **MQTT**: Mosquitto broker on localhost:1883
- **Port**: 5051 (Flask application)

### Hardware Requirements
- **Camera**: USB or Raspberry Pi camera module
- **ESP32**: WiFi microcontroller
- **Motor Driver**: BTS7960 H-bridge (2 units)
- **Motors**: DC motors with wheels

---

## üìä Code Statistics

| Metric | Value |
|--------|-------|
| Total Lines of Code | 600+ |
| Python Code | 332 lines (3 files) |
| HTML/CSS/JS | 450+ lines |
| Documentation | 900+ lines |
| Configuration | 10 lines |
| Total Size | ~50 KB (without dependencies) |

---

## üéØ Key Features Implementation

### Feature: Real-time Person Detection
- **File**: `app.py` (lines 131-169)
- **Method**: MediaPipe Holistic model
- **Input**: Camera frame (640√ó480)
- **Output**: 33 pose landmarks with confidence

### Feature: Position Analysis
- **File**: `app.py` (lines 70-100)
- **Logic**: Normalize nose X coordinate to frame width
- **Zones**: LEFT (0-35%), CENTER (35-65%), RIGHT (65-100%)
- **Tolerance**: ¬±15% for center detection

### Feature: Depth Estimation
- **File**: `app.py` (lines 101-119)
- **Logic**: Calculate shoulder width, invert to get distance
- **Ranges**: NEAR (<30%), MEDIUM (30-70%), FAR (>70%)
- **Landmarks Used**: Left shoulder (11) & Right shoulder (12)

### Feature: Command Generation
- **File**: `app.py` (lines 160-180)
- **Decision Tree**: 5-branch logic (FAR‚ÜíF, NEAR‚ÜíB, L‚ÜíL, R‚ÜíR, CENTER‚ÜíS)
- **MQTT Publishing**: JSON format with cmd and speed
- **Topic**: robot/control

### Feature: Web Interface
- **File**: `templates/index.html`
- **Framework**: Flask + Vanilla JS
- **Streaming**: MJPEG (multipart/x-mixed-replace)
- **Updates**: 500ms polling for status
- **Responsive**: Adapts to desktop and mobile

### Feature: Threshold Adjustment
- **Route**: POST /set_threshold
- **Parameters**: near_threshold, far_threshold
- **Range**: 0.1-0.5 (near), 0.5-0.9 (far)
- **Update**: Real-time without app restart

---

## üîÑ Data Flow

```
Camera Input
    ‚Üì
Frame Capture (640√ó480)
    ‚Üì
MediaPipe Processing
    ‚Üì
Landmark Extraction (33 points)
    ‚Üì
Position Analysis (X coordinate of nose)
    ‚Üì
Depth Analysis (Shoulder width)
    ‚Üì
Decision Engine
    ‚Üì
MQTT Publish
    ‚Üì
{"cmd": "F/B/L/R/S", "speed": 200}
    ‚Üì
Web Status Update
    ‚Üì
Display in Browser
    ‚Üì
ESP32 Receives ‚Üí Motor Control
```

---

## üöÄ Deployment Checklist

- [ ] All files created in correct locations
- [ ] Dependencies specified in requirements.txt
- [ ] app.py has all required imports
- [ ] templates/index.html properly formatted
- [ ] MQTT broker running (Mosquitto)
- [ ] Camera connected and working
- [ ] Network connectivity verified
- [ ] Thresholds adjusted for environment
- [ ] Web interface accessible on port 5051
- [ ] MQTT messages verified with mosquitto_sub
- [ ] Robot responds to MQTT commands
- [ ] FPS meets minimum requirements (15+)

---

## üìö File Dependencies Tree

```
app.py
‚îú‚îÄ‚îÄ Flask (web framework)
‚îú‚îÄ‚îÄ cv2 (OpenCV)
‚îÇ   ‚îî‚îÄ‚îÄ Camera capture & frame encoding
‚îú‚îÄ‚îÄ mediapipe (pose detection)
‚îÇ   ‚îî‚îÄ‚îÄ Holistic model & landmarks
‚îú‚îÄ‚îÄ paho.mqtt.client
‚îÇ   ‚îî‚îÄ‚îÄ MQTT publishing
‚îî‚îÄ‚îÄ numpy (numerical operations)

templates/index.html
‚îú‚îÄ‚îÄ Flask routes (/) 
‚îú‚îÄ‚îÄ Video stream (/video_feed)
‚îú‚îÄ‚îÄ Status endpoint (/status)
‚îî‚îÄ‚îÄ Threshold setter (/set_threshold)

test_setup.py
‚îú‚îÄ‚îÄ cv2 (camera test)
‚îú‚îÄ‚îÄ mediapipe (import test)
‚îú‚îÄ‚îÄ mqtt.client (connection test)
‚îî‚îÄ‚îÄ subprocess (system check)

viewer.py
‚îú‚îÄ‚îÄ cv2 (camera & display)
‚îú‚îÄ‚îÄ mediapipe (skeleton overlay)
‚îî‚îÄ‚îÄ numpy (calculations)
```

---

## üîê Security Notes

### Current Security Posture
- **MQTT**: Anonymous connections allowed (development only)
- **Flask**: No authentication
- **Network**: Local network only

### Recommendations for Production
1. Enable MQTT authentication
2. Add Flask login/API key
3. Use HTTPS/TLS for web interface
4. Restrict network access
5. Implement rate limiting
6. Add input validation

---

## üéì Learning Outcomes

After implementing this module, you'll understand:

1. **Computer Vision**: Real-time pose detection with MediaPipe
2. **Flask**: Building web servers with video streaming
3. **MQTT**: IoT message publishing and subscripting
4. **Robotics**: Autonomous following algorithms
5. **Python**: Advanced threading and state management
6. **Web Development**: Real-time web interfaces
7. **System Integration**: Connecting hardware and software

---

## üìû Support & Troubleshooting

### Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| Camera not found | Check USB connection, run test_setup.py |
| No person detected | Improve lighting, ensure full body visible |
| MQTT not publishing | Verify broker running: `sudo systemctl status mosquitto` |
| Web interface unresponsive | Check port 5051 open, restart Flask |
| High CPU usage | Reduce resolution, skip frames, lighter model |
| Low FPS | Increase lighting, reduce processing |

### Debug Commands
```bash
# Test camera
python -c "import cv2; cap = cv2.VideoCapture(0); print(cap.isOpened())"

# Test MediaPipe
python -c "import mediapipe; print('OK')"

# Test MQTT
mosquitto_pub -h 127.0.0.1 -p 1883 -t test -m "hello"

# Monitor MQTT
mosquitto_sub -h 127.0.0.1 -p 1883 -t "robot/control"

# Check port
netstat -tuln | grep 5051
```

---

## üìà Performance Tuning

### To Improve FPS
1. Reduce FRAME_WIDTH and FRAME_HEIGHT
2. Skip frames (process every 2nd/3rd frame)
3. Use model_complexity=0 (lighter model)
4. Reduce detection confidence threshold

### To Improve Accuracy
1. Improve lighting conditions
2. Increase detection confidence threshold
3. Use full body in frame
4. Reduce background clutter

### To Reduce Latency
1. Reduce MQTT publish frequency
2. Use local MQTT broker (not cloud)
3. Optimize network bandwidth
4. Skip non-critical status updates

---

## ‚úÖ Verification Checklist

After setup, verify:

- [ ] All 8 files present in module directory
- [ ] Python files have correct syntax
- [ ] HTML file loads without errors
- [ ] requirements.txt has all dependencies
- [ ] Documentation files are readable
- [ ] Camera accessible via OpenCV
- [ ] MediaPipe models loaded successfully
- [ ] MQTT broker accepting connections
- [ ] Flask app starts without errors
- [ ] Web interface appears at :5051
- [ ] Video stream loads and shows camera
- [ ] Detection status updates in real-time
- [ ] MQTT commands publish correctly
- [ ] Threshold sliders work
- [ ] FPS ‚â• 15

---

**Module Status**: ‚úÖ Complete
**Ready for Deployment**: Yes
**Last Updated**: 28 January 2026
**Tested On**: Raspberry Pi 4B with USB camera
**Python Version**: 3.10.0

---

For quick start: See **QUICKSTART.md**
For detailed guide: See **IMPLEMENTATION_GUIDE.md**
For technical deep-dive: See **HUMAN_DETECTION_GUIDE.md**
